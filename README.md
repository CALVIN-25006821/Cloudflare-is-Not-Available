# Cloudflare-is-Not-Available

# Hybrid AI Credit Scoring System

This project uses a hybrid approach to assess credit risk, combining a *Random Forest model* (Math Brain) for structured financial data and *Google Gemini* (Text Brain) for analyzing unstructured user stories.

## ğŸš€ Step-by-Step Setup Guide

Follow these instructions to get the project running on your local machine.

### 1. Prerequisites
- Python 3.9 or higher
- A Google Gemini API Key (Get one [here](https://aistudio.google.com/app/apikey))

### 2. Set up the Environment

1.  *Clone/Download* this repository.
2.  *Create a Virtual Environment* (recommended to keep dependencies isolated):
    bash
    python3 -m venv .venv
    source .venv/bin/activate  # On Windows use: .venv\Scripts\activate
    
3.  *Install Dependencies*:
    bash
    pip install -r requirements.txt
    

### 3. Configure API Key

1.  Create a file named .env in the root directory.
2.  Add your Gemini API key to it:
    env
    GEMINI_API_KEY=your_actual_api_key_here
    

### 4. Train the Model (The "Math Brain")

Before running the app, you need to generate the machine learning model.

1.  Run the training script:
    bash
    python train_model.py
    
2.  *What happens:*
    - Generates synthetic Malaysian loan data.
    - Trains a Random Forest model.
    - Saves baseline_model_rf.pkl (The Model) and cleaned_data.csv (The Data).
    - You should see "âœ… All done!" when finished.

### 5. Run the Application

You have two options to run the system:

#### Option A: Interactive Dashboard (Streamlit) - *RECOMMENDED*
This is the user-friendly web interface.

1.  Run the app:
    bash
    streamlit run app.py
    
2.  Open your browser at the URL shown (usually http://localhost:8501).
3.  Enter applicant details and a story to see the AI assessment.

#### Option B: Backend API (FastAPI)
If you want to use the system as a REST API for other apps.

1.  Start the server:
    bash
    uvicorn main:app --reload
    
2.  Access the API documentation at http://127.0.0.1:8000/docs.

## ğŸ“‚ Project Structure

- *app.py*: The frontend dashboard (Streamlit).
- *risk_engine.py*: The core logic combining Math + Text models.
- *train_model.py*: Generates data and trains the Random Forest model.
- *main.py*: The backend API (FastAPI).
- *requirements.txt*: List of Python libraries needed.
- *baseline_model_rf.pkl*: The saved "Math Brain" model.

â–¶ï¸ How to Run

â€¢ Run backend

â€¢ uvicorn main:app --reload

â€¢ Run Streamlit

â€¢ streamlit run app.py

Streamlit APP: https://hackathon112025-sxahghfka9xuedaeytk5hv.streamlit.app/ 

---

ğŸ§© Roles & Responsibilities

1. Calvin Kong Hao Xuan â€” Data Scientist

Deliverables:

â€¢ Cleaned structured dataset

â€¢ Baseline ML models (Logistic Regression & Random Forest)

â€¢ Google Colab notebook

<br>

Work Summary:

â€¢ Preprocess raw credit dataset

â€¢ Feature selection (income, DTI, loan ratio, credit history, etc.)

â€¢ Train baseline models

â€¢ Evaluate using AUC & F1

â€¢ Export cleaned_data.csv + models

---

2. Choo Kah Lok â€” LLM Engineer

Deliverables:

â€¢ LLM prompts

â€¢ Text feature extraction notebook

â€¢ text_features.csv

<br>

Work Summary:

â€¢ Generate synthetic loan-purpose descriptions

â€¢ Extract sentiment, risk patterns, urgency, financial behaviour

â€¢ Convert text into numeric features

---

3. Soo Kang Shi â€” Fusion Model Engineer

Deliverables:

â€¢ Fusion dataset

â€¢ SHAP explainability

â€¢ final_model.pkl

<br>

Work Summary:

â€¢ Merge structured + text features

â€¢ Train fusion model

â€¢ Hyperparameter tuning

â€¢ Generate SHAP visuals + explanations

---

4. Leow Shen En â€” Streamlit UI Developer

Deliverables:

â€¢ app.py (Streamlit app)

<br>

Work Summary:

â€¢ Build clean input form

â€¢ Connect to prediction backend

â€¢ Show final score & explanation

â€¢ Plot feature importance

---

5. Priscilia Cheong Ee Cheng â€” Documentation Lead

Deliverables:

â€¢ Project report

â€¢ Architecture diagrams

â€¢ Presentation script


<br>
Work Summary:

â€¢ Create system diagrams

â€¢ Write methodology & justification

â€¢ Prepare presentation

---

ğŸ›ï¸ System Architecture

â€¢ User (Streamlit UI)
<br>

â€¢ FastAPI Backend

-> Random Forest Model â€“ Structured Risk

-> LLM (Gemini/OpenAI) â€“ Text Analysis (Behavioural Risk)

â€¢ Fusion Layer â€“ 70% ML + 30% LLM

â€¢ Final Risk Score + Explanation


---

ğŸ”„ Project Workflow

Step 1 â€” Data Generation & Cleaning

â€¢ Synthetic Malaysian credit dataset

â€¢ Feature engineering

â€¢ Missing value handling
<br>


Step 2 â€” Baseline ML

â€¢ Train LR + RF

â€¢ Evaluate

â€¢ Export .pkl models
<br>


Step 3 â€” LLM Text Extraction 

â€¢ Gemini prompts

â€¢ Extract text-based behavioural features

â€¢ Generate text_features.csv
<br>


Step 4 â€” Fusion Model 

â€¢ Merge datasets

â€¢ Train final model

â€¢ SHAP interpretability
<br>


Step 5 â€” FastAPI Backend

â€¢ Endpoint: /predict

â€¢ Loads RF model

â€¢ Calls LLM

â€¢ Returns final score + explanation
<br>


Step 6 â€” Streamlit Dashboard

â€¢ User inputs

â€¢ Calls backend

â€¢ Displays prediction + charts
<br>


---

ğŸ§  Fusion Logic

Structured Risk (RF Model Input)

â€¢ Age

â€¢ Income

â€¢ Loan amount

â€¢ Loan term

â€¢ DTI

â€¢ Credit history

â€¢ Dependents


Output: Probability of default (0â€“1)


---

Text Risk (LLM Input)

â€¢ Analyzes loan-purpose description for:

â€¢ Sentiment

â€¢ Responsibility

â€¢ Urgency / stress

â€¢ Red flags

â€¢ Clarity


Output: Text risk score (0â€“1)


---

Final Fusion Formula

final_score = (0.7 Ã— structured_risk) + (0.3 Ã— text_risk)

Decision rule:

Score > 0.5 â†’ REJECT

Score â‰¤ 0.5 â†’ APPROVE


---

ğŸ“‚ Folder Structure


ğŸ“ data/ â€“ Contains datasets

ğŸ“„ cleaned_data.csv â€“ Preprocessed dataset

ğŸ“„ text_features.csv â€“ Extracted text features
<br>

ğŸ“ models/ â€“ Saved machine learning models

ğŸ“„ baseline_model_lr.pkl â€“ Logistic Regression baseline

ğŸ“„ baseline_model_rf.pkl â€“ Random Forest baseline

ğŸ“„ final_model.pkl â€“ Final tuned model
<br>

ğŸ“ backend/ â€“ FastAPI backend code

ğŸ“„ main.py â€“ API entry point

ğŸ“„ risk_engine.py â€“ Core risk assessment logic
<br>

ğŸ“ ui/ â€“ User interface

ğŸ“„ app.py â€“ Frontend (Streamlit/FastAPI)
<br>

ğŸ“ notebooks/ â€“ Jupyter notebooks for experimentation

ğŸ“„ structured_data.ipynb â€“ Structured data analysis

ğŸ“„ text_analysis.ipynb â€“ NLP/text feature analysis

ğŸ“„ fusion_model.ipynb â€“ ML + LLM fusion experiments

ğŸ“„ README.md â€“ Project documentation
<br>

---

â­ Project Highlights

â€¢ Hybrid ML + LLM risk assessment

â€¢ Fairer and more explainable than traditional scoring

â€¢ Malaysian-style synthetic dataset

â€¢ SHAP interpretability

â€¢ Real-time dashboard

â€¢ Modular design for easy extension
